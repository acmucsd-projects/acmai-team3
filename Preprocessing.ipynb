{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "path_train = r'data/train'\n",
    "path_test = r'data/test'\n",
    "files_train = sorted(os.listdir(path_train))\n",
    "files_test = sorted(os.listdir(path_test))\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Labels-Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Class Labels\n",
    "Exp_train = files_train\n",
    "Exp_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Image Preprocessing-training data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3995/3995 [00:01<00:00, 2438.28it/s]\n",
      "100%|██████████| 4097/4097 [00:01<00:00, 2434.70it/s]\n",
      "100%|██████████| 7215/7215 [00:02<00:00, 2438.52it/s]\n",
      "100%|██████████| 4965/4965 [00:02<00:00, 2338.07it/s]\n",
      "100%|██████████| 4830/4830 [00:01<00:00, 2421.91it/s]\n",
      "100%|██████████| 3171/3171 [00:01<00:00, 2473.91it/s]\n"
     ]
    }
   ],
   "source": [
    "i_train=0\n",
    "last_train=[]\n",
    "images_train=[]\n",
    "labels_train=[]\n",
    "# look into glob\n",
    "for fle in files_train:\n",
    "    idx=Exp_train.index(fle)\n",
    "    label=idx\n",
    "\n",
    "    total=path_train+'/'+fle\n",
    "    files_exp= os.listdir(total)\n",
    "#     print('FILES_EXP', files_exp )\n",
    "#     print(len(files_exp))\n",
    "    for fle_2 in tqdm(files_exp, total = len(files_exp)):\n",
    "        file_main=total+'/'+fle_2\n",
    "        image= cv2.imread(file_main)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image= cv2.resize(image,(48,48))\n",
    "        images_train.append(image)\n",
    "        labels_train.append(label)\n",
    "        i_train+=1\n",
    "    last_train.append(i_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3995, 1: 4097, 2: 7215, 3: 4965, 4: 4830, 5: 3171})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See number of each class\n",
    "Counter(labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Balance Training Dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even Each class to same amount\n",
    "min_train = 3171\n",
    "class_0 = labels_train[:3995]\n",
    "class_1 = labels_train[3995:(3995 + 4107)]\n",
    "class_2 = labels_train[(3995 + 4107):(3995 + 4107 + 7228)]\n",
    "class_3 = labels_train[(3995 + 4107 + 7228):(3995 + 4107 + 7228 + 4965)]\n",
    "class_4 = labels_train[(3995 + 4107 + 7228 + 4965):(3995 + 4107 + 7228 + 4965 + 4830)]\n",
    "class_5 = labels_train[(3995 + 4107 + 7228 + 4965 + 4830):(3995 + 4107 + 7228 + 4965 + 4830 + 3171)]\n",
    "class_0_img = images_train[:3995]\n",
    "class_1_img = images_train[3995:(3995 + 4107)]\n",
    "class_2_img = images_train[(3995 + 4107):(3995 + 4107 + 7228)]\n",
    "class_3_img = images_train[(3995 + 4107 + 7228):(3995 + 4107 + 7228 + 4965)]\n",
    "class_4_img = images_train[(3995 + 4107 + 7228 + 4965):(3995 + 4107 + 7228 + 4965 + 4830)]\n",
    "class_5_img = images_train[(3995 + 4107 + 7228 + 4965 + 4830):(3995 + 4107 + 7228 + 4965 + 4830 + 3171)]\n",
    "\n",
    "classes_train = [[class_0, class_0_img], [class_1, class_1_img], [class_2, class_2_img], [class_3, class_3_img],\n",
    "           [class_4, class_4_img], [class_5, class_5_img]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in classes_train:\n",
    "    temp = list(zip(x[0], x[1]))\n",
    "    random.shuffle(temp)\n",
    "    temp = temp[:min_train]\n",
    "    x[0], x[1] = zip(*temp)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = classes_train[0][0]\n",
    "class_1 = classes_train[1][0]\n",
    "class_2 = classes_train[2][0]\n",
    "class_3 = classes_train[3][0]\n",
    "class_4 = classes_train[4][0]\n",
    "class_5 = classes_train[5][0]\n",
    "class_0_img = classes_train[0][1]\n",
    "class_1_img = classes_train[1][1]\n",
    "class_2_img = classes_train[2][1]\n",
    "class_3_img = classes_train[3][1]\n",
    "class_4_img = classes_train[4][1]\n",
    "class_5_img = classes_train[5][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = class_0 + class_1 + class_2 + class_3 + class_4 + class_5 \n",
    "images_train = class_0_img + class_1_img + class_2_img + class_3_img + class_4_img + class_5_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3171, 1: 3163, 2: 3168, 3: 3167, 4: 3173, 5: 3161})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19003"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19003"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of Images/Converting labels and Images into NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images_f_train = np.array(images_train)\n",
    "#labels_f_train = np.array(labels_train)\n",
    "#images_f_2_train = images_f_train/255\n",
    "#labels_train_encoded = tf.keras.utils.to_categorical(labels_f_train, num_classes = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Labels-Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Labels\n",
    "Exp_test = files_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Image Preprocessing-Test Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 958/958 [00:00<00:00, 2391.82it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 2917.01it/s]\n",
      "100%|██████████| 1774/1774 [00:00<00:00, 2572.00it/s]\n",
      "100%|██████████| 1233/1233 [00:00<00:00, 2754.26it/s]\n",
      "100%|██████████| 1247/1247 [00:00<00:00, 2763.10it/s]\n",
      "100%|██████████| 831/831 [00:00<00:00, 3105.50it/s]\n"
     ]
    }
   ],
   "source": [
    "i_test=0\n",
    "last_test=[]\n",
    "images_test=[]\n",
    "labels_test=[]\n",
    "# look into glob\n",
    "for fle in files_test:\n",
    "    idx=Exp_test.index(fle)\n",
    "    label=idx\n",
    "\n",
    "    total=path_test+'/'+fle\n",
    "    files_exp= os.listdir(total)\n",
    "#     print('FILES_EXP', files_exp )\n",
    "#     print(len(files_exp))\n",
    "    for fle_2 in tqdm(files_exp, total = len(files_exp)):\n",
    "        file_main=total+'/'+fle_2\n",
    "        image= cv2.imread(file_main)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image= cv2.resize(image,(48,48))\n",
    "        images_test.append(image)\n",
    "        labels_test.append(label)\n",
    "        i_test+=1\n",
    "    last_test.append(i_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 958, 1: 1024, 2: 1774, 3: 1233, 4: 1247, 5: 831})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See number of each class\n",
    "Counter(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Balance Testing Dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even Each class to same amount\n",
    "min_test = 831\n",
    "class_0_test = labels_test[:968]\n",
    "class_1_test = labels_test[968:(968 + 1024)]\n",
    "class_2_test = labels_test[(968 + 1024):(968 + 1024 + 1774)]\n",
    "class_3_test = labels_test[(968 + 1024 + 1774):(968 + 1024 + 1774 + 1233)]\n",
    "class_4_test = labels_test[(968 + 1024 + 1774 + 1233):(968 + 1024 + 1774 + 1233 + 1245)]\n",
    "class_5_test = labels_test[(968 + 1024 + 1774 + 1233 + 1245):(968 + 1024 + 1774 + 1233 + 1245 + 831)]\n",
    "class_0_img_test = images_test[:968]\n",
    "class_1_img_test = images_test[968:(968 + 1024)]\n",
    "class_2_img_test = images_test[(968 + 1024):(968 + 1024 + 1774)]\n",
    "class_3_img_test = images_test[(968 + 1024 + 1774):(968 + 1024 + 1774 + 1233)]\n",
    "class_4_img_test = images_test[(968 + 1024 + 1774 + 1233):(968 + 1024 + 1774 + 1233 + 1245)]\n",
    "class_5_img_test = images_test[(968 + 1024 + 1774 + 1233 + 1245):(968 + 1024 + 1774 + 1233 + 1245 + 831)]\n",
    "\n",
    "classes_test = [[class_0_test, class_0_img_test], [class_1_test, class_1_img_test], [class_2_test, class_2_img_test], [class_3_test, class_3_img_test],\n",
    "           [class_4_test, class_4_img_test], [class_5_test, class_5_img_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in classes_test:\n",
    "    temp = list(zip(x[0], x[1]))\n",
    "    random.shuffle(temp)\n",
    "    temp = temp[:min_test]\n",
    "    x[0], x[1] = zip(*temp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0_test = classes_test[0][0]\n",
    "class_1_test = classes_test[1][0]\n",
    "class_2_test = classes_test[2][0]\n",
    "class_3_test = classes_test[3][0]\n",
    "class_4_test = classes_test[4][0]\n",
    "class_5_test = classes_test[5][0]\n",
    "class_0_img_test = classes_test[0][1]\n",
    "class_1_img_test = classes_test[1][1]\n",
    "class_2_img_test = classes_test[2][1]\n",
    "class_3_img_test = classes_test[3][1]\n",
    "class_4_img_test = classes_test[4][1]\n",
    "class_5_img_test = classes_test[5][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = class_0_test + class_1_test + class_2_test + class_3_test + class_4_test + class_5_test\n",
    "images_test = class_0_img_test + class_1_img_test + class_2_img_test + class_3_img_test + class_4_img_test + class_5_img_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 825, 1: 828, 2: 839, 3: 827, 4: 831, 5: 828})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_train + labels_test\n",
    "images = images_train + images_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(zip(labels, images))\n",
    "random.shuffle(temp)\n",
    "labels, images = zip(*temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_split = int(0.7 * len(labels))\n",
    "train_images_split = int(0.7 * len(images))\n",
    "val_labels_split = int(0.2 * len(labels))\n",
    "val_images_split = int(0.2 * len(images))\n",
    "test_labels_split = int(0.1 * len(labels))\n",
    "test_images_split = int(0.1 * len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = images[:train_images_split]\n",
    "Y_train = labels[:train_labels_split]\n",
    "X_val = images[train_images_split:(train_images_split + val_images_split)]\n",
    "Y_val = labels[train_labels_split:(train_labels_split + val_labels_split)]\n",
    "X_test = images[(train_images_split + val_images_split):]\n",
    "Y_test = labels[(train_labels_split + val_labels_split):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "images_f_train = np.array(X_train)\n",
    "labels_f_train = np.array(Y_train)\n",
    "images_f_2_train = images_f_train/255\n",
    "labels_train_encoded = tf.keras.utils.to_categorical(labels_f_train, num_classes = 6)\n",
    "\n",
    "# validation\n",
    "images_f_val = np.array(X_val)\n",
    "labels_f_val = np.array(Y_val)\n",
    "images_f_2_val = images_f_val/255\n",
    "labels_val_encoded = tf.keras.utils.to_categorical(labels_f_val, num_classes = 6)\n",
    "\n",
    "# test\n",
    "images_f_test = np.array(X_test)\n",
    "labels_f_test = np.array(Y_test)\n",
    "images_f_2_test = images_f_test/255\n",
    "labels_test_encoded = tf.keras.utils.to_categorical(labels_f_test, num_classes = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = images_f_2_train\n",
    "Y_train = labels_train_encoded\n",
    "X_val = images_f_2_val\n",
    "Y_val = labels_val_encoded\n",
    "X_test = images_f_2_test\n",
    "Y_test = labels_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16786"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16786"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4796"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4796"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2399"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2399"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train', X_train)\n",
    "np.save('Y_train', Y_train)\n",
    "np.save('X_val', X_val)\n",
    "np.save('Y_val', Y_val)\n",
    "np.save('X_test', X_test)\n",
    "np.save('Y_test', Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten,BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D,Conv2D\n",
    "from tensorflow.keras.layers import Input,Activation,Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def Convolution(input_tensor,filters):\n",
    "    \n",
    "    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1))(input_tensor)\n",
    "    #x = Dropout(0.1)(x)\n",
    "    x= Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "def model(input_shape):\n",
    "    inputs = Input((input_shape))\n",
    "  \n",
    "    conv_1= Convolution(inputs,16)\n",
    "    maxp_1 = MaxPooling2D(pool_size = (2,2)) (conv_1)\n",
    "    conv_2 = Convolution(maxp_1,32)\n",
    "    maxp_2 = MaxPooling2D(pool_size = (2, 2)) (conv_2)\n",
    "    #conv_3 = Convolution(maxp_2,128)\n",
    "    #maxp_3 = MaxPooling2D(pool_size = (2, 2)) (conv_3)\n",
    "    #conv_4 = Convolution(maxp_3,256)\n",
    "    #maxp_4 = MaxPooling2D(pool_size = (2, 2)) (conv_4)\n",
    "    flatten= Flatten() (maxp_2)\n",
    "    dense_1= Dense(16,activation='relu')(flatten)\n",
    "    #drop_1=Dropout(0.2)(dense_1)\n",
    "    output= Dense(6,activation=\"sigmoid\")(dense_1)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model=model(input_shape = (48,48,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "History=Model.fit(X_train,Y_train,batch_size=6,validation_data=(X_test,Y_test),epochs=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
