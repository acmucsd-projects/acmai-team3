{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "path_train = r'data/train'\n",
    "path_test = r'data/test'\n",
    "files_train = sorted(os.listdir(path_train))\n",
    "files_test = sorted(os.listdir(path_test))\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Labels-Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Labels\n",
    "Exp_train = files_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exp_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Preprocessing-training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3995/3995 [00:01<00:00, 2463.18it/s]\n",
      "100%|██████████| 4097/4097 [00:01<00:00, 2578.56it/s]\n",
      "100%|██████████| 7215/7215 [00:02<00:00, 2514.00it/s]\n",
      "100%|██████████| 4965/4965 [00:02<00:00, 2428.39it/s]\n",
      "100%|██████████| 4830/4830 [00:01<00:00, 2643.61it/s]\n",
      "100%|██████████| 3171/3171 [00:01<00:00, 2562.49it/s]\n"
     ]
    }
   ],
   "source": [
    "i_train=0\n",
    "last_train=[]\n",
    "images_train=[]\n",
    "labels_train=[]\n",
    "# look into glob\n",
    "for fle in files_train:\n",
    "    idx=Exp_train.index(fle)\n",
    "    label=idx\n",
    "\n",
    "    total=path_train+'/'+fle\n",
    "    files_exp= os.listdir(total)\n",
    "#     print('FILES_EXP', files_exp )\n",
    "#     print(len(files_exp))\n",
    "    for fle_2 in tqdm(files_exp, total = len(files_exp)):\n",
    "        file_main=total+'/'+fle_2\n",
    "        image= cv2.imread(file_main)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image= cv2.resize(image,(48,48))\n",
    "        images_train.append(image)\n",
    "        labels_train.append(label)\n",
    "        i_train+=1\n",
    "    last_train.append(i_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3995, 1: 4097, 2: 7215, 3: 4965, 4: 4830, 5: 3171})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See number of each class\n",
    "Counter(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28273"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28273"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even Each class to same amount\n",
    "min_train = 3171\n",
    "class_0 = labels_train[:3995]\n",
    "class_1 = labels_train[3995:(3995 + 4107)]\n",
    "class_2 = labels_train[(3995 + 4107):(3995 + 4107 + 7228)]\n",
    "class_3 = labels_train[(3995 + 4107 + 7228):(3995 + 4107 + 7228 + 4965)]\n",
    "class_4 = labels_train[(3995 + 4107 + 7228 + 4965):(3995 + 4107 + 7228 + 4965 + 4830)]\n",
    "class_5 = labels_train[(3995 + 4107 + 7228 + 4965 + 4830):(3995 + 4107 + 7228 + 4965 + 4830 + 3171)]\n",
    "class_0_img = images_train[:3995]\n",
    "class_1_img = images_train[3995:(3995 + 4107)]\n",
    "class_2_img = images_train[(3995 + 4107):(3995 + 4107 + 7228)]\n",
    "class_3_img = images_train[(3995 + 4107 + 7228):(3995 + 4107 + 7228 + 4965)]\n",
    "class_4_img = images_train[(3995 + 4107 + 7228 + 4965):(3995 + 4107 + 7228 + 4965 + 4830)]\n",
    "class_5_img = images_train[(3995 + 4107 + 7228 + 4965 + 4830):(3995 + 4107 + 7228 + 4965 + 4830 + 3171)]\n",
    "\n",
    "classes_train = [[class_0, class_0_img], [class_1, class_1_img], [class_2, class_2_img], [class_3, class_3_img],\n",
    "           [class_4, class_4_img], [class_5, class_5_img]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in classes_train:\n",
    "    temp = list(zip(x[0], x[1]))\n",
    "    random.shuffle(temp)\n",
    "    temp = temp[:min_train]\n",
    "    x[0], x[1] = zip(*temp)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = classes_train[0][0]\n",
    "class_1 = classes_train[1][0]\n",
    "class_2 = classes_train[2][0]\n",
    "class_3 = classes_train[3][0]\n",
    "class_4 = classes_train[4][0]\n",
    "class_5 = classes_train[5][0]\n",
    "class_0_img = classes_train[0][1]\n",
    "class_1_img = classes_train[1][1]\n",
    "class_2_img = classes_train[2][1]\n",
    "class_3_img = classes_train[3][1]\n",
    "class_4_img = classes_train[4][1]\n",
    "class_5_img = classes_train[5][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = class_0 + class_1 + class_2 + class_3 + class_4 + class_5 \n",
    "images_train = class_0_img + class_1_img + class_2_img + class_3_img + class_4_img + class_5_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3171, 1: 3164, 2: 3167, 3: 3165, 4: 3171, 5: 3165})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19003"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19003"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of Images/Converting labels and Images into NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_f_train = np.array(images_train)\n",
    "labels_f_train = np.array(labels_train)\n",
    "images_f_2_train = images_f_train/255\n",
    "labels_train_encoded = tf.keras.utils.to_categorical(labels_f_train, num_classes = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19003"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_train_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Labels-Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Labels\n",
    "Exp_test = files_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Preprocessing-Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 958/958 [00:00<00:00, 2791.32it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 2921.46it/s]\n",
      "100%|██████████| 1774/1774 [00:00<00:00, 2742.06it/s]\n",
      "100%|██████████| 1233/1233 [00:00<00:00, 2830.34it/s]\n",
      "100%|██████████| 1247/1247 [00:00<00:00, 2807.89it/s]\n",
      "100%|██████████| 831/831 [00:00<00:00, 3036.37it/s]\n"
     ]
    }
   ],
   "source": [
    "i_test=0\n",
    "last_test=[]\n",
    "images_test=[]\n",
    "labels_test=[]\n",
    "# look into glob\n",
    "for fle in files_test:\n",
    "    idx=Exp_test.index(fle)\n",
    "    label=idx\n",
    "\n",
    "    total=path_test+'/'+fle\n",
    "    files_exp= os.listdir(total)\n",
    "#     print('FILES_EXP', files_exp )\n",
    "#     print(len(files_exp))\n",
    "    for fle_2 in tqdm(files_exp, total = len(files_exp)):\n",
    "        file_main=total+'/'+fle_2\n",
    "        image= cv2.imread(file_main)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image= cv2.resize(image,(48,48))\n",
    "        images_test.append(image)\n",
    "        labels_test.append(label)\n",
    "        i_test+=1\n",
    "    last_test.append(i_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 958, 1: 1024, 2: 1774, 3: 1233, 4: 1247, 5: 831})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See number of each class\n",
    "Counter(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7067"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7067"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Even Each class to same amount\n",
    "min_test = 831\n",
    "class_0_test = labels_test[:968]\n",
    "class_1_test = labels_test[968:(968 + 1024)]\n",
    "class_2_test = labels_test[(968 + 1024):(968 + 1024 + 1774)]\n",
    "class_3_test = labels_test[(968 + 1024 + 1774):(968 + 1024 + 1774 + 1233)]\n",
    "class_4_test = labels_test[(968 + 1024 + 1774 + 1233):(968 + 1024 + 1774 + 1233 + 1245)]\n",
    "class_5_test = labels_test[(968 + 1024 + 1774 + 1233 + 1245):(968 + 1024 + 1774 + 1233 + 1245 + 831)]\n",
    "class_0_img_test = images_test[:968]\n",
    "class_1_img_test = images_test[968:(968 + 1024)]\n",
    "class_2_img_test = images_test[(968 + 1024):(968 + 1024 + 1774)]\n",
    "class_3_img_test = images_test[(968 + 1024 + 1774):(968 + 1024 + 1774 + 1233)]\n",
    "class_4_img_test = images_test[(968 + 1024 + 1774 + 1233):(968 + 1024 + 1774 + 1233 + 1245)]\n",
    "class_5_img_test = images_test[(968 + 1024 + 1774 + 1233 + 1245):(968 + 1024 + 1774 + 1233 + 1245 + 831)]\n",
    "\n",
    "classes_test = [[class_0_test, class_0_img_test], [class_1_test, class_1_img_test], [class_2_test, class_2_img_test], [class_3_test, class_3_img_test],\n",
    "           [class_4_test, class_4_img_test], [class_5_test, class_5_img_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in classes_test:\n",
    "    temp = list(zip(x[0], x[1]))\n",
    "    random.shuffle(temp)\n",
    "    temp = temp[:min_test]\n",
    "    x[0], x[1] = zip(*temp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0_test = classes_test[0][0]\n",
    "class_1_test = classes_test[1][0]\n",
    "class_2_test = classes_test[2][0]\n",
    "class_3_test = classes_test[3][0]\n",
    "class_4_test = classes_test[4][0]\n",
    "class_5_test = classes_test[5][0]\n",
    "class_0_img_test = classes_test[0][1]\n",
    "class_1_img_test = classes_test[1][1]\n",
    "class_2_img_test = classes_test[2][1]\n",
    "class_3_img_test = classes_test[3][1]\n",
    "class_4_img_test = classes_test[4][1]\n",
    "class_5_img_test = classes_test[5][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = class_0_test + class_1_test + class_2_test + class_3_test + class_4_test + class_5_test\n",
    "images_test = class_0_img_test + class_1_img_test + class_2_img_test + class_3_img_test + class_4_img_test + class_5_img_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 831, 0: 822, 2: 836, 3: 827, 4: 832, 5: 830})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4978"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4978"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of Images/Converting labels and Images into NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_f_test = np.array(images_test)\n",
    "labels_f_test = np.array(labels_test)\n",
    "images_f_2_test = images_f_test/255\n",
    "labels_test_encoded = tf.keras.utils.to_categorical(labels_f_test, num_classes = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4978"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = images_f_2_train\n",
    "Y_train = labels_train_encoded\n",
    "X_test = images_f_2_test \n",
    "Y_test = labels_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19003"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19003"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4978"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4978"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten,BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D,Conv2D\n",
    "from tensorflow.keras.layers import Input,Activation,Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def Convolution(input_tensor,filters):\n",
    "    \n",
    "    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1))(input_tensor)\n",
    "    #x = Dropout(0.1)(x)\n",
    "    x= Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "def model(input_shape):\n",
    "    inputs = Input((input_shape))\n",
    "  \n",
    "    conv_1= Convolution(inputs,16)\n",
    "    maxp_1 = MaxPooling2D(pool_size = (2,2)) (conv_1)\n",
    "    conv_2 = Convolution(maxp_1,32)\n",
    "    maxp_2 = MaxPooling2D(pool_size = (2, 2)) (conv_2)\n",
    "    #conv_3 = Convolution(maxp_2,128)\n",
    "    #maxp_3 = MaxPooling2D(pool_size = (2, 2)) (conv_3)\n",
    "    #conv_4 = Convolution(maxp_3,256)\n",
    "    #maxp_4 = MaxPooling2D(pool_size = (2, 2)) (conv_4)\n",
    "    flatten= Flatten() (maxp_2)\n",
    "    dense_1= Dense(16,activation='relu')(flatten)\n",
    "    #drop_1=Dropout(0.2)(dense_1)\n",
    "    output= Dense(6,activation=\"sigmoid\")(dense_1)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model=model(input_shape = (48,48,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3168/3168 [==============================] - 19s 6ms/step - loss: 1.6370 - accuracy: 0.3051 - val_loss: 1.5323 - val_accuracy: 0.3871\n",
      "Epoch 2/10\n",
      "3168/3168 [==============================] - 18s 6ms/step - loss: 1.4357 - accuracy: 0.4302 - val_loss: 1.4206 - val_accuracy: 0.4337\n",
      "Epoch 3/10\n",
      "3168/3168 [==============================] - 18s 6ms/step - loss: 1.3305 - accuracy: 0.4799 - val_loss: 1.3641 - val_accuracy: 0.4624\n",
      "Epoch 4/10\n",
      "3168/3168 [==============================] - 19s 6ms/step - loss: 1.2579 - accuracy: 0.5086 - val_loss: 1.3677 - val_accuracy: 0.4608\n",
      "Epoch 5/10\n",
      "3168/3168 [==============================] - 19s 6ms/step - loss: 1.1909 - accuracy: 0.5405 - val_loss: 1.3531 - val_accuracy: 0.4697\n",
      "Epoch 6/10\n",
      "3168/3168 [==============================] - 19s 6ms/step - loss: 1.1312 - accuracy: 0.5641 - val_loss: 1.3921 - val_accuracy: 0.4620\n",
      "Epoch 7/10\n",
      "3168/3168 [==============================] - 19s 6ms/step - loss: 1.0692 - accuracy: 0.5914 - val_loss: 1.4544 - val_accuracy: 0.4616\n",
      "Epoch 8/10\n",
      "3168/3168 [==============================] - 19s 6ms/step - loss: 1.0138 - accuracy: 0.6129 - val_loss: 1.4359 - val_accuracy: 0.4669\n",
      "Epoch 9/10\n",
      "3168/3168 [==============================] - 20s 6ms/step - loss: 0.9632 - accuracy: 0.6321 - val_loss: 1.4762 - val_accuracy: 0.4652\n",
      "Epoch 10/10\n",
      "3168/3168 [==============================] - 19s 6ms/step - loss: 0.9163 - accuracy: 0.6522 - val_loss: 1.5676 - val_accuracy: 0.4500\n"
     ]
    }
   ],
   "source": [
    "History=Model.fit(X_train,Y_train,batch_size=6,validation_data=(X_test,Y_test),epochs=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
